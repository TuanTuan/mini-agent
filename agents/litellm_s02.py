#!/usr/bin/env python3
"""
litellm_s02.py - Tools (LiteLLM/OpenAI Format)

åŸºäº s02_tool_use.pyï¼Œä½¿ç”¨ LiteLLM SDK å’Œ OpenAI æ¶ˆæ¯æ ¼å¼ã€‚
The agent loop didn't change. We just added tools to the array
and a dispatch map to route calls.

    +----------+      +-------+      +------------------+
    |   User   | ---> |  LLM  | ---> | Tool Dispatch    |
    |  prompt  |      |       |      | {                |
    +----------+      +---+---+      |   bash: run_bash |
                          ^          |   read: run_read |
                          |          |   write: run_wr  |
                          +----------+   edit: run_edit |
                          tool_result| }                |
                                     +------------------+

Key insight: "The loop didn't change at all. I just added tools."

ç¯å¢ƒå˜é‡:
    AZURE_API_KEY      - Azure API å¯†é’¥
    AZURE_API_BASE     - Azure ç«¯ç‚¹ URL
    AZURE_API_VERSION  - API ç‰ˆæœ¬
    AZURE_DEPLOYMENT   - éƒ¨ç½²åç§° (é»˜è®¤ gpt-5.2)

å‘½ä»¤è¡Œå‚æ•°:
    python litellm_s02.py                    # é»˜è®¤ï¼šç»ˆç«¯è¯¦ç»†æ—¥å¿— + æ˜¾ç¤ºRAW
    python litellm_s02.py -q                 # å®‰é™æ¨¡å¼ï¼šä¸åœ¨ç»ˆç«¯æ˜¾ç¤ºæ—¥å¿—
    python litellm_s02.py -o session.md      # è¾“å‡ºåˆ°Markdownæ–‡ä»¶
"""

import json
import os
import subprocess
from pathlib import Path

import litellm
from dotenv import load_dotenv

from logger_openai import create_logger_from_args, parse_logger_args, get_logger_config_string

load_dotenv(override=True)

# ============================================================================
# é…ç½®
# ============================================================================
AZURE_API_KEY = os.getenv("AZURE_API_KEY", "")
AZURE_API_BASE = os.getenv("AZURE_API_BASE", "")
AZURE_API_VERSION = os.getenv("AZURE_API_VERSION", "2024-02-15-preview")
AZURE_DEPLOYMENT = os.getenv("AZURE_DEPLOYMENT", "gpt-5.2")

WORKDIR = Path.cwd()
MODEL = f"azure/{AZURE_DEPLOYMENT}"
SYSTEM_PROMPT = f"You are a coding agent at {WORKDIR}. Use tools to solve tasks. Act, don't explain."

# è§£æå‘½ä»¤è¡Œå‚æ•°å¹¶åˆå§‹åŒ–æ—¥å¿—å™¨
_args = parse_logger_args()
logger = create_logger_from_args(_args)


def safe_path(p: str) -> Path:
    """ç¡®ä¿è·¯å¾„ä¸é€ƒé€¸å·¥ä½œç›®å½•"""
    path = (WORKDIR / p).resolve()
    if not path.is_relative_to(WORKDIR):
        raise ValueError(f"Path escapes workspace: {p}")
    return path


def run_bash(command: str) -> str:
    """æ‰§è¡Œ shell å‘½ä»¤"""
    dangerous = ["rm -rf /", "sudo", "shutdown", "reboot", "> /dev/"]
    if any(d in command for d in dangerous):
        return "Error: Dangerous command blocked"
    try:
        r = subprocess.run(command, shell=True, cwd=WORKDIR,
                           capture_output=True, text=True, timeout=120)
        out = (r.stdout + r.stderr).strip()
        return out[:50000] if out else "(no output)"
    except subprocess.TimeoutExpired:
        return "Error: Timeout (120s)"


def run_read(path: str, limit: int = None) -> str:
    """è¯»å–æ–‡ä»¶å†…å®¹"""
    try:
        text = safe_path(path).read_text()
        lines = text.splitlines()
        if limit and limit < len(lines):
            lines = lines[:limit] + [f"... ({len(lines) - limit} more lines)"]
        return "\n".join(lines)[:50000]
    except Exception as e:
        return f"Error: {e}"


def run_write(path: str, content: str) -> str:
    """å†™å…¥æ–‡ä»¶"""
    try:
        fp = safe_path(path)
        fp.parent.mkdir(parents=True, exist_ok=True)
        fp.write_text(content)
        return f"Wrote {len(content)} bytes to {path}"
    except Exception as e:
        return f"Error: {e}"


def run_edit(path: str, old_text: str, new_text: str) -> str:
    """ç¼–è¾‘æ–‡ä»¶ï¼ˆæ›¿æ¢æ–‡æœ¬ï¼‰"""
    try:
        fp = safe_path(path)
        content = fp.read_text()
        if old_text not in content:
            return f"Error: Text not found in {path}"
        fp.write_text(content.replace(old_text, new_text, 1))
        return f"Edited {path}"
    except Exception as e:
        return f"Error: {e}"


# -- The dispatch map: {tool_name: handler} --
TOOL_HANDLERS = {
    "bash":       lambda **kw: run_bash(kw["command"]),
    "read_file":  lambda **kw: run_read(kw["path"], kw.get("limit")),
    "write_file": lambda **kw: run_write(kw["path"], kw["content"]),
    "edit_file":  lambda **kw: run_edit(kw["path"], kw["old_text"], kw["new_text"]),
}

# -- OpenAI æ ¼å¼çš„å·¥å…·å®šä¹‰ --
TOOLS = [
    {
        "type": "function",
        "function": {
            "name": "bash",
            "description": "Run a shell command.",
            "parameters": {
                "type": "object",
                "properties": {"command": {"type": "string"}},
                "required": ["command"],
            },
        },
    },
    {
        "type": "function",
        "function": {
            "name": "read_file",
            "description": "Read file contents.",
            "parameters": {
                "type": "object",
                "properties": {
                    "path": {"type": "string"},
                    "limit": {"type": "integer", "description": "Optional line limit"}
                },
                "required": ["path"],
            },
        },
    },
    {
        "type": "function",
        "function": {
            "name": "write_file",
            "description": "Write content to file.",
            "parameters": {
                "type": "object",
                "properties": {
                    "path": {"type": "string"},
                    "content": {"type": "string"}
                },
                "required": ["path", "content"],
            },
        },
    },
    {
        "type": "function",
        "function": {
            "name": "edit_file",
            "description": "Replace exact text in file.",
            "parameters": {
                "type": "object",
                "properties": {
                    "path": {"type": "string"},
                    "old_text": {"type": "string"},
                    "new_text": {"type": "string"}
                },
                "required": ["path", "old_text", "new_text"],
            },
        },
    },
]


# ============================================================================
# Agent Loop
# ============================================================================
def agent_loop(messages: list):
    """
    æ ¸å¿ƒ Agent å¾ªç¯

    OpenAI å“åº”ç»“æ„:
    {
        "choices": [{
            "message": {
                "role": "assistant",
                "content": "...",
                "tool_calls": [{"id": "...", "function": {"name": "...", "arguments": "..."}}]
            },
            "finish_reason": "tool_calls" | "stop"
        }],
        "usage": {"prompt_tokens": N, "completion_tokens": N}
    }
    """
    iteration = 0

    while True:
        iteration += 1
        logger.loop_iteration(iteration)

        # æ˜¾ç¤ºè°ƒç”¨ LLM å‰çš„æ¶ˆæ¯çŠ¶æ€
        logger.messages_snapshot(messages, "BEFORE LLM CALL")

        # ========== æ˜¾ç¤ºåŸå§‹ API è¯·æ±‚æ•°æ® ==========
        logger.request_raw(
            model=MODEL,
            messages=messages,
            tools=TOOLS,
            max_tokens=8000
        )

        # è°ƒç”¨ LiteLLM
        response = litellm.completion(
            model=MODEL,
            messages=messages,
            tools=TOOLS,
            api_key=AZURE_API_KEY,
            api_base=AZURE_API_BASE,
            api_version=AZURE_API_VERSION,
        )

        # è½¬æ¢ä¸ºå­—å…¸
        response_dict = response.model_dump() if hasattr(response, 'model_dump') else dict(response)

        # ========== æ˜¾ç¤ºåŸå§‹ API å“åº”æ•°æ® ==========
        logger.response_raw(response_dict)

        # æå–å“åº”ä¿¡æ¯
        choice = (response_dict.get("choices") or [{}])[0] or {}
        message = choice.get("message") or {}
        finish_reason = choice.get("finish_reason") or "stop"
        tool_calls = message.get("tool_calls") or []
        usage = response_dict.get("usage") or {}

        # æ˜¾ç¤º LLM å“åº”æ‘˜è¦
        logger.llm_response_summary(
            finish_reason,
            {"prompt_tokens": usage.get("prompt_tokens", 0), "completion_tokens": usage.get("completion_tokens", 0)},
            len(tool_calls)
        )

        # è¿½åŠ  assistant æ¶ˆæ¯
        assistant_msg = {"role": "assistant", "content": message.get("content") or ""}
        if tool_calls:
            assistant_msg["tool_calls"] = tool_calls
        messages.append(assistant_msg)

        logger.messages_snapshot(messages, "AFTER APPEND ASSISTANT")

        # å¦‚æœæ¨¡å‹æ²¡æœ‰è°ƒç”¨å·¥å…·ï¼Œå¾ªç¯ç»“æŸ
        if finish_reason != "tool_calls":
            logger.loop_end(f"finish_reason = '{finish_reason}'")
            return

        # æ‰§è¡Œå·¥å…·è°ƒç”¨
        logger.section("Executing Tool Calls", "ğŸ”§")
        for tc in tool_calls:
            tc_id = tc.get("id", "")
            fn = tc.get("function") or {}
            fn_name = fn.get("name", "")
            fn_args_str = fn.get("arguments", "{}")

            try:
                fn_args = json.loads(fn_args_str) if isinstance(fn_args_str, str) else fn_args_str
            except json.JSONDecodeError:
                fn_args = {}

            # æ˜¾ç¤ºå·¥å…·è°ƒç”¨
            logger.tool_call(fn_name, fn_args, tc_id)

            # æ‰§è¡Œå·¥å…·
            handler = TOOL_HANDLERS.get(fn_name)
            output = handler(**fn_args) if handler else f"Unknown tool: {fn_name}"
            print(f"\033[33m> {fn_name}:\033[0m {output[:200]}")

            # æ˜¾ç¤ºå·¥å…·ç»“æœ
            is_error = output.startswith("Error:")
            logger.tool_result(tc_id, output, is_error=is_error)

            # è¿½åŠ  tool ç»“æœæ¶ˆæ¯
            messages.append({
                "role": "tool",
                "tool_call_id": tc_id,
                "content": output,
            })

        logger.messages_snapshot(messages, "AFTER APPEND TOOL RESULTS")
        logger.separator(f"END OF ITERATION {iteration}")


# ============================================================================
# ä¸»ç¨‹åº
# ============================================================================
if __name__ == "__main__":
    logger.header("LiteLLM Multi-Tool - Azure GPT-5.2", "litellm-s02")
    logger.config(
        model=MODEL,
        api_base=AZURE_API_BASE,
        api_version=AZURE_API_VERSION
    )

    # æ˜¾ç¤ºå½“å‰æ—¥å¿—é…ç½®
    print(logger._color(f"\n  âš™ï¸ Logger Config: {get_logger_config_string(_args)}", "dim"))
    if _args.log_file:
        print(logger._color(f"  ğŸ“ Log file: {_args.log_file}", "dim"))
    print()

    # OpenAI æ ¼å¼: system æ˜¯ç¬¬ä¸€æ¡æ¶ˆæ¯
    history = [{"role": "system", "content": SYSTEM_PROMPT}]

    while True:
        try:
            query = input("\033[36mlitellm-s02 >> \033[0m")
        except (EOFError, KeyboardInterrupt):
            break
        if query.strip().lower() in ("q", "exit", ""):
            break

        logger.user_input(query)
        history.append({"role": "user", "content": query})
        agent_loop(history)

        logger.separator("FINAL RESPONSE")
        # è·å–æœ€åçš„ assistant æ¶ˆæ¯
        for msg in reversed(history):
            if msg.get("role") == "assistant":
                content = msg.get("content")
                if content:
                    print(content)
                break
        print()

    # ç»“æŸä¼šè¯
    logger.session_end("ç”¨æˆ·é€€å‡º")
